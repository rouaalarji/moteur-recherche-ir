{
  "id": 14,
  "title": "Réseau de neurones artificiels",
  "url": "https://fr.wikipedia.org/wiki/R%C3%A9seau_neuronal_artificiel",
  "date": "2025-11-29T22:26:58.295893",
  "content": "Pour les articles homonymes, voir Réseau de neurones (biologie) et Réseau (homonymie) .\nmodifier - modifier le code - modifier Wikidata\nUn réseau de neurones artificiels [ 1 ] , [ 2 ] , ou réseau neuronal artificiel [ 1 ] , est un système informatique dont la conception est inspirée à l'origine du fonctionnement des neurones mais qui, par la suite, s'est rapproché des méthodes statistiques [ 3 ] .\nLes réseaux de neurones artificiels sont généralement optimisés par des méthodes d'apprentissage de type probabiliste, en particulier bayésien . Ils sont placés d'une part dans la famille des applications statistiques , qu'ils enrichissent avec un ensemble de paradigmes [ 4 ] permettant de créer des classifications rapides ( réseaux de Kohonen en particulier), et d'autre part dans la famille des méthodes de l' intelligence artificielle auxquelles ils fournissent un mécanisme perceptif indépendant des idées propres de l'implémenteur, et des informations d'entrée au raisonnement logique formel (voir Apprentissage profond ).\nEn modélisation des circuits biologiques, ils permettent de tester quelques hypothèses fonctionnelles issues de la neurophysiologie , ou encore les conséquences de ces hypothèses pour les comparer au réel.\nLes réseaux neuronaux sont construits sur un paradigme biologique , celui du neurone formel (comme les algorithmes génétiques le sont sur la sélection naturelle ). Ce type de métaphore biologique est devenu courant avec les idées de la cybernétique et biocybernétique .\nLes neurologues Warren McCulloch et Walter Pitts publient à la fin des années 1950 des travaux sur les réseaux de neurones, dont on retient l'article fondateur « What the frog’s eye tells the frog’s brain » (« Ce que l'œil d'une grenouille dit au cerveau d'une grenouille ») [ 5 ] . Ils construisent un modèle de neurone, communément appelé neurone formel , et montrent que des réseaux de neurones formels simples peuvent théoriquement réaliser des fonctions logiques , arithmétiques et symboliques complexes.\nLe neurone formel est conçu comme un automate doté d'une fonction de transfert qui transforme ses entrées en sortie selon des règles précises. Par exemple, un neurone additionne ses valeurs d'entrée, compare la somme résultante à une valeur de seuil, et émet un signal si cette somme est supérieure ou égale au seuil (modèle ultra-simplifié du fonctionnement d'un neurone biologique). Ces neurones sont par ailleurs associés en réseaux dont la topologie des connexions est variable : réseaux proactifs, récurrents , etc. Enfin, l'efficacité de la  transmission des signaux d'un neurone à l'autre peut varier : on parle de poids synaptique susceptibles d'être modulés par des règles d'apprentissage (ce qui mime la plasticité synaptique des réseaux biologiques).\nUne fonction des réseaux de neurones formels, à l'instar du modèle vivant, est d'opérer rapidement des classifications et d'apprendre à les améliorer. À l'opposé des méthodes traditionnelles de résolution informatique , on ne doit pas construire un programme pas à pas en fonction de la compréhension de celui-ci. Les paramètres importants de ce modèle sont les coefficients synaptiques et le seuil de chaque neurone, et la façon de les ajuster. Ce sont eux qui déterminent l'évolution du réseau en fonction de ses informations d'entrée. Il faut choisir un mécanisme permettant de les calculer et de les faire converger si possible vers une valeur assurant une classification aussi proche que possible de l'optimale. C'est ce qu'on nomme la phase d'apprentissage du réseau. Dans un modèle de réseau de neurones formels, apprendre revient donc à déterminer les coefficients synaptiques les plus adaptés à classifier les exemples présentés.\nWarren McCulloch (qui veut « comprendre comment on comprend ») et Walter Pitts publient en 1943 l'un des articles considéré comme ayant lancé la mode de l'intelligence artificielle : « A logical calculus of the ideas immanent in nervous activity », Bulletin of Mathematical Biophysics ,‎ 1943 ( lire en ligne ) . Ils considèrent que le fonctionnement des neurones naturels évoque celui des portes logiques en électronique. Mais ils ne donnent pas d'indication méthodologique pour calculer la valeur des « coefficients synaptiques ». Cette question est pourtant au cœur des réflexions sur l'apprentissage, et connait un début de réponse grâce aux travaux du physiologiste canadien Donald Hebb en 1949 ( The Organization of Behaviour [ 6 ] ). Donald Hebb propose une règle permettant d'adapter la valeur des « coefficients synaptiques » à l'activité des unités qu'ils relient. Cette règle, connue sous le nom de « règle de Hebb », est présente presque partout dans les modèles actuels, même les plus sophistiqués.\nL'idée de « coefficients synaptiques » qui s'auto-adaptent amène le psychologue Frank Rosenblatt à proposer en 1958 le modèle du perceptron [ 7 ] . C'est le premier système artificiel capable d'apprendre par expérience, y compris quand son instructeur commet des erreurs (ce en quoi il diffère nettement d'un système d'apprentissage logique formel). Les médias américains, dont le New York Times , publient une vague d'articles enthousiastes et annoncent pour bientôt une machine capable de tout reconnaitre, de penser, de marcher, se reproduire. Certains déclarent que le perceptron pourra bientôt faire de l' exploration spatiale . Le magazine Science dit que le perceptron pourra apprendre, prendre des décisions et traduire des langues [ 8 ] .\nWarren McCulloch , interviewé par Radio Canada en 1969 (peu avant son décès), explique que :\n« les machines informatiques pensent avec un langage qui est celui des nombres ; nous transformons tout en chiffre pour les faire fonctionner. Elles sont nulles en matière de perception. Elles n'ont pas de langage naturel sous-jacent, comme nous ou les animaux. Lorsqu'on veut les faire développer un modèle de monde autour d'elles-mêmes, on s'aperçoit que ce n'est pas le bon dispositif. Vous voulez qu'elles jouent aux échecs, très bien. Notre programme de jeux d'échec au MIT est déjà un joueur de 2 e rang ; dans un an je pense qu'il sera de 1 er rang ; ce sera pas un maitre au bout d'un an mais dans six ans environ. Dans six ans, il deviendra une technologie de 1 er rang qu'aucun humain ne pourra dépasser. Je souhaite que ca aille plus loin, et ça ira plus loin, car nous pouvons réduire ces choses là à des nombres [ 8 ] . »\nCette même année 1969, un coup d'arrêt est donné à cette piste par Marvin Lee Minsky et Seymour Papert , qui estiment qu'imiter le cerveau est trop complexe. Ces derniers co-publient un ouvrage conséquent, pédagogique et apparemment complet, intitulé Perceptrons [ 9 ] , mettant en exergue certaines des limitations théoriques, selon eux insurmontables, du perceptron, et plus généralement des classifieurs linéaires ; ces derniers ne peuvent pas traiter des problèmes non linéaires ou de connexité (par exemple, le cas de la fonction XOR ) [ 10 ] . Minsky et Paperts étendent implicitement ces limitations à tous modèles de réseaux de neurones artificiels. Paraissant alors dans une impasse, la Recherche sur les réseaux de neurones perd l'essentiel de ses financements publics, et le secteur industriel s'en détourna aussi. Les fonds destinés à l' intelligence artificielle furent redirigés plutôt vers la logique formelle [ 11 ] . Cependant, les solides qualités de certains réseaux de neurones en matière adaptative (exemple : Adaline ), leur permettant de modéliser de façon évolutive des phénomènes eux-mêmes évolutifs, les amèneront à être intégrés sous des formes plus ou moins explicites dans le corpus des systèmes adaptatifs; utilisés dans le domaine des télécommunications ou celui du contrôle de processus industriels.\nEn 1982, John Joseph Hopfield donne un nouveau souffle à la métaphore neuronale avec son article introduisant un nouveau modèle de réseau de neurones dit de Hopfield [ 12 ] . L'article connait le succès pour plusieurs raisons, dont la principale est de teinter la théorie des réseaux de neurones de la rigueur propre aux physiciens. Le neuronal redevient un sujet d'étude acceptable, bien que le modèle souffre des limitations des modèles des années 1960 , notamment l'impossibilité de traiter les problèmes non linéaires.\nEn 1970, Seppo Linnainmaa publie la méthode générale de dérivation automatique (DA) des réseaux connectés discrets de fonctions différentiables imbriquées. En 1973, Dreyfus utilise la rétropropagation pour adapter les paramètres des contrôleurs proportionnellement aux gradients d'erreur.\nL'algorithme de rétropropagation du gradient est formellement établi par Paul Werbos en 1974 [ 13 ] , et permet l'entraînement pratique des réseaux multicouches. En 1982, il a appliqué la méthode AD de Seppo Linnainmaa aux réseaux neuronaux de la manière qui est devenue largement utilisée [ 14 ] , [ 15 ] . Son application est popularisé dans le perceptron multi-couche développé en 1986 par David Rumelhart , Ronald J. Williams et Geoffrey Hinton [ 16 ] .\nLes réseaux de neurones connaissent par la suite un essor considérable, dû en partie au développement de l' électronique numérique qui fournit davantage de puissance de calcul pour le développement de réseaux neuronaux artificiels dans les années 1980.\nCes systèmes bénéficieront de l'éclairage de la théorie de la « régularisation statistique » introduite par Vladimir Vapnik en Union soviétique et popularisée en Occident depuis la chute du mur. [ réf. souhaitée] Cette théorie, l'une des plus importantes du domaine des statistiques , permet d'anticiper, d'étudier et de réguler les phénomènes liés au surapprentissage . Le surapprentissage est une difficulté à laquelle doivent faire face tous les systèmes d'apprentissage par l'exemple, que ceux-ci utilisent des méthodes d' optimisation directe (exemple : régression linéaire ), itératives (exemple : l' algorithme du gradient ), ou itératives semi-directes ( gradient conjugué , espérance-maximisation ...) et que ceux-ci soient appliqués aux modèles statistiques classiques, aux modèles de Markov cachés ou aux réseaux de neurones formels [ 17 ] .\nLes réseaux de neurones évoluent avec un nouveau type de réseau non complètement connecté, pour alléger les modèles en nombre de paramètres, et améliorer les performances et leur capacité de généralisation. Une des premières applications a été la reconnaissance automatique des codes postaux aux États-Unis , avec le réseau LeNet-5 [ 18 ] . En apprentissage automatique, un réseau de neurones convolutifs ou réseau de neurones à convolution (en anglais CNN ou ConvNet pour Convolutional Neural Networks) est un type de réseau de neurones artificiels acycliques (feed-forward), dans lequel le motif de connexion entre les neurones est inspiré par le cortex visuel des animaux. Les neurones de cette région du cerveau sont arrangés de sorte qu'ils correspondent à des régions qui se chevauchent lors du pavage du champ visuel. Leur fonctionnement est inspiré par les processus biologiques, ils consistent en un empilage multicouche de perceptrons, dont le but est de prétraiter de petites quantités d'informations. Les réseaux neuronaux convolutifs ont de larges applications dans la reconnaissance d'image et vidéo, les systèmes de recommandation et le traitement du langage naturel.\nGrâce à leur capacité de classification et de généralisation, les réseaux de neurones sont généralement utilisés dans des problèmes de nature statistique.\nLes réseaux de neurones sont réellement utilisés, par exemple [ 19 ] :\nUn réseau de neurones est en général composé d'une succession de couches dont chacune prend ses entrées sur les sorties de la précédente. Chaque couche (i) est composée de N i neurones, prenant leurs entrées sur les N i-1 neurones de la couche précédente. À chaque synapse est associé un poids synaptique, de sorte que les N i-1 sont multipliés par ce poids, puis additionnés par les neurones de niveau i, ce qui est équivalent à multiplier le vecteur d'entrée par une matrice de transformation. Mettre l'une derrière l'autre les différentes couches d'un réseau de neurones reviendrait à mettre en cascade plusieurs matrices de transformation et pourrait se ramener à une seule matrice, produit des autres, s'il n'y avait à chaque couche, la fonction de sortie qui introduit une non linéarité à chaque étape. Ceci montre l'importance du choix judicieux d'une bonne fonction de sortie : un réseau de neurones dont les sorties seraient linéaires n'aurait aucun intérêt.\nAu-delà de cette structure simple, le réseau de neurones peut également contenir des boucles qui en changent radicalement les possibilités mais aussi la complexité. De la même façon que des boucles peuvent transformer une logique combinatoire en logique séquentielle , les boucles dans un réseau de neurones transforment un simple dispositif de reconnaissance d'entrées en une machine complexe capable de toutes sortes de comportements.\nConsidérons un neurone quelconque.\nIl reçoit des neurones en amont un certain nombre de valeurs via ses connexions synaptiques, et il produit une certaine valeur en utilisant une fonction de combinaison.\nCette fonction peut donc être formalisée comme étant une fonction vecteur -à- scalaire , notamment :\nLa fonction d'activation (ou fonction de seuillage ou encore fonction de transfert) sert à introduire une non-linéarité dans le fonctionnement du neurone.\nLes fonctions de seuillage présentent généralement trois intervalles :\nDes exemples classiques de fonctions d'activation sont :\nLa logique bayésienne, dont le théorème de Cox-Jaynes formalise les questions d'apprentissage, fait intervenir aussi une fonction en S qui revient de façon récurrente : e v ( p ) = 10 log ⁡ ( p 1 − p ) {\\displaystyle ev(p)=10\\log \\left({\\frac {p}{1-p}}\\right)}\nCe calcul effectué, le neurone propage son nouvel état interne sur son axone.\nDans un modèle simple, la fonction neuronale est simplement une fonction de seuillage : elle vaut 1 si la somme pondérée dépasse un certain seuil ; 0 sinon.\nDans un modèle plus riche, le neurone fonctionne avec des nombres réels (souvent compris dans l'intervalle [0,1] ou [-1,1]).\nOn dit que le réseau de neurones passe d'un état à un autre lorsque tous ses neurones recalculent en parallèle leur état interne, en fonction de leurs entrées.\nL'apprentissage, connu depuis Sumer [réf. nécessaire] , est peu modélisable par la logique déductive : cette dernière procède à partir de connaissances déjà établies dont on tire des connaissances dérivées. Or l'apprentissage emploie la démarche inverse: des observations limitées mènent à des généralisations plausibles, suivant une logique inductive .\nLa notion de généralisation est traitée de façon plus ou moins complète par plusieurs approches théoriques.\nEn fonction de la structure du réseau, différents types de fonction sont approchables grâce aux réseaux de neurones :\nUn perceptron (un réseau à une unité) accepte les fonctions booléennes suivantes : ET , OU , NON-ET , NON-OU mais pas le OU-exclusif . Comme toute fonction booléenne est représentable à l'aide de ces fonctions, un réseau de perceptrons est capable de représenter toutes les fonctions booléennes. En effet les fonctions NON-ET et NON-OU sont dites universelles : on peut par combinaison de l'une de ces fonctions représenter toutes les autres.\nLa large majorité des réseaux de neurones possède un algorithme « d’entraînement » qui consiste à modifier les poids synaptiques en fonction d'un jeu de données présentées en entrée du réseau, par descente de gradient . Le but de cet entraînement est de permettre au réseau de neurones d'« apprendre » à partir des exemples. Si l'entraînement est correctement réalisé, le réseau est capable de fournir des réponses en sortie très proches des valeurs d'origine du jeu de données d'entraînement. Mais tout l'intérêt des réseaux de neurones réside dans leur capacité à généraliser à partir du jeu de test. Il est donc possible d'utiliser un réseau de neurones pour réaliser une mémoire ; on parle alors de mémoire neuronale.\nLa vision topologique d'un apprentissage correspond à la détermination de l' hypersurface sur R n {\\displaystyle \\mathbb {R} ^{n}} où R {\\displaystyle \\mathbb {R} } est l' ensemble des réels , et n {\\displaystyle n} le nombre d'entrées du réseau.\nUn apprentissage est dit supervisé lorsque le réseau est forcé à converger vers un état final précis, en même temps qu'un motif lui est présenté.\nÀ l'inverse, lors d'un apprentissage non-supervisé, le réseau est laissé libre de converger vers n'importe quel état final lorsqu'un motif lui est présenté.\nIl arrive souvent que les exemples de la base d'apprentissage comportent des valeurs approximatives ou bruitées. Si on oblige le réseau à répondre de façon quasi parfaite relativement à ces exemples, on peut obtenir un réseau qui est biaisé par des valeurs erronées.\nPar exemple, imaginons qu'on présente au réseau des couples ( x i , f ( x i ) ) {\\displaystyle (x_{i},f(x_{i}))} situés sur une droite d'équation y = a x + b {\\displaystyle y=ax+b} , mais bruités de sorte que les points ne soient pas exactement sur la droite. S'il y a un bon apprentissage, le réseau répond a x + b {\\displaystyle ax+b} pour toute valeur de x {\\displaystyle x} présentée. S'il y a surapprentissage , le réseau répond un peu plus que a x + b {\\displaystyle ax+b} ou un peu moins, car chaque couple ( x i , f ( x i ) ) {\\displaystyle (x_{i},f(x_{i}))} positionné en dehors de la droite va influencer la décision : il aura appris le bruit en plus, ce qui n'est pas souhaitable.\nPour éviter le surapprentissage, il existe une méthode simple : il suffit de partager la base d'exemples en deux sous-ensembles. Le premier sert à l'apprentissage et le second sert à l'évaluation de l'apprentissage. Tant que l'erreur obtenue sur le deuxième ensemble diminue, on peut continuer l'apprentissage, sinon on arrête.\nLa rétropropagation consiste à rétropropager l'erreur commise par un neurone à ses synapses et aux neurones qui y sont reliés. Pour les réseaux de neurones, on utilise habituellement la rétropropagation du gradient de l'erreur , qui consiste à corriger les erreurs selon l'importance des éléments qui ont justement participé à la réalisation de ces erreurs : les poids synaptiques qui contribuent à engendrer une erreur importante se verront modifiés de manière plus significative que les poids qui ont engendré une erreur marginale.\nL'élagage ( pruning , en anglais) est une méthode qui permet d'éviter le surapprentissage tout en limitant la complexité du modèle. Elle consiste à supprimer des connexions (ou synapses), des entrées ou des neurones du réseau une fois l'apprentissage terminé. En pratique, les éléments qui ont la plus petite influence sur l'erreur de sortie du réseau sont supprimés. Deux exemples d'algorithmes d'élagage sont :\nLes réseaux de neurones artificiels ont besoin de cas réels servant d'exemples pour leur apprentissage (on appelle cela la base d'apprentissage ). Ces cas doivent être d'autant plus nombreux que le problème est complexe et que sa topologie est peu structurée. Ainsi on peut optimiser un système neuronal de lecture de caractères en utilisant le découpage manuel d'un grand nombre de mots écrits à la main par de nombreuses personnes. Chaque caractère peut alors être présenté sous la forme d'une image brute, disposant d'une topologie spatiale à deux dimensions, ou d'une suite de segments presque tous liés. La topologie retenue, la complexité du phénomène modélisé, et le nombre d'exemples doivent être en rapport. Sur un plan pratique, cela n'est pas toujours facile car les exemples peuvent être soit en quantité absolument limitée ou trop onéreux à collecter en nombre suffisant.\nIl y a des problèmes qui se traitent bien avec les réseaux de neurones, en particulier ceux de classification en domaines convexes (c'est-à-dire tels que si des points A et B font partie du domaine, alors tout le segment AB en fait partie aussi). Des problèmes comme « Le nombre d'entrées à 1 (ou à zéro) est-il pair ou impair ? » se résolvent en revanche mal : pour affirmer de telles choses sur 2 puissance N points, si on se contente d'une approche naïve mais homogène, il faut précisément N-1 couches de neurones intermédiaires, ce qui nuit à la généralité du procédé.\nUn exemple caricatural, mais significatif est le suivant : disposant en entrée du seul poids d'une personne, le réseau doit déterminer si cette personne est une femme ou bien un homme. Les femmes étant statistiquement plus légères que les hommes, le réseau fera toujours un peu mieux qu'un simple tirage au hasard : cet exemple dépouillé indique la simplicité et les limitations de ces modèles mais il montre également comment l'étendre : l'information « port d'une jupe », si on l'ajoute, aurait clairement un coefficient synaptique plus grand que la simple information de poids.\nLes réseaux complexes de neurones artificiels ne peuvent généralement pas expliquer eux-mêmes leur façon de « penser ». Les calculs aboutissant à un résultat ne sont pas visibles pour les programmeurs qui ont créé le réseau neuronal [ 21 ] . Une « neuroscience de l'intelligence artificielle » a donc été créée pour étudier la boîte noire que constituent les réseaux de neurones, science qui pourrait permettre d'augmenter la confiance dans les résultats produits par ces réseaux ou les intelligences artificielles qui les utilisent [ 21 ] .\nL'optimisation des hyperparamètres est une étape complexe et critique permettant d'assurer la convergence et l'efficacité du réseau de neurones. Il existe des méthodes de test des différents hyperparamètres utilisant des fonctions spécifiques de convergence vers les meilleurs hyperparamètres.\nL'ensemble des poids des liaisons synaptiques détermine le fonctionnement du réseau de neurones. Les motifs sont présentés à un sous-ensemble du réseau de neurones : la couche d'entrée. Lorsqu'un motif est appliqué à un réseau, celui-ci cherche à atteindre un état stable. Lorsqu'il est atteint, les valeurs d'activation des neurones de sortie constituent le résultat. Les neurones qui ne font ni partie de la couche d'entrée ni de la couche de sortie sont dits neurones cachés .\nLes types de réseau de neurones diffèrent par plusieurs paramètres :\nDe nombreux autres paramètres sont susceptibles d'être mis en œuvre dans le cadre de l'apprentissage de ces réseaux de neurones par exemple :\nLe réseau ADALINE est proche du modèle perceptron , seule sa fonction d'activation est différente puisqu'il utilise une fonction linéaire. Afin de réduire les parasites reçus en entrée, les réseaux ADALINE utilisent la méthode des moindres carrés .\nLe réseau réalise une somme pondérée de ses valeurs d'entrées et y rajoute une valeur de seuil prédéfinie. La fonction de transfert linéaire est ensuite utilisée pour l'activation du neurone. Lors de l'apprentissage, les coefficients synaptiques des différentes entrées sont modifiés en utilisant la loi de Widrow-Hoff (en) . Ces réseaux sont souvent employés en traitement de signaux [ 22 ] , notamment pour la réduction de bruit.\nUne machine de Cauchy est un réseau de neurones artificiels assez proche dans le fonctionnement d'une machine de Boltzmann . Cependant les lois de probabilités utilisées ne sont pas les mêmes [ 23 ] .\nDans ce type d'apprentissage non supervisé, les neurones sont en compétition pour être actifs. Ils sont à sortie binaire et on dit qu'ils sont actifs lorsque leur sortie vaut 1. Alors que dans les autres règles plusieurs sorties de neurones peuvent être actives simultanément, dans le cas de l'apprentissage compétitif, un seul neurone est actif à un instant donné. Chaque neurone de sortie est spécialisé pour « détecter » une suite de formes similaires et devient alors un détecteur de caractéristiques. La fonction d'entrée est dans ce cas, h = b - d i s t ⁡ ( W , X ) {\\displaystyle h=\\operatorname {b-dist} (W,X)} où b {\\displaystyle b} , W {\\displaystyle W} et X {\\displaystyle X} sont respectivement les vecteurs seuil, poids synaptiques et entrées. Le neurone gagnant est celui pour lequel h est maximum donc si les seuils sont identiques, celui dont les poids sont les plus proches des entrées. Le neurone dont la sortie est maximale sera le vainqueur et sa sortie sera mise à 1 alors que les perdants auront leur sortie mise à 0. Un neurone apprend en déplaçant ses poids vers les valeurs des entrées qui l'activent pour augmenter ses chances de gagner. Si un neurone ne répond pas à une entrée, aucun ajustement de poids n'intervient. Si un neurone gagne, une portion des poids de toutes les entrées est redistribuée vers les poids des entrées actives. L'application de la règle donne les résultats suivants (Grossberg) :\nCette règle a pour effet de rapprocher le vecteur poids synaptique w i j {\\displaystyle w_{ij}} de la forme d'entrée x j {\\displaystyle x_{j}} .\nExemple : considérons deux nuages de points du plan que l'on désire séparer en deux classes. x 1 {\\displaystyle x_{1}} et x 2 {\\displaystyle x_{2}} sont les deux entrées, w 11 {\\displaystyle w_{11}} et w 12 {\\displaystyle w_{12}} sont les poids du neurone 1 que l'on peut considérer comme les coordonnées d'un point ‘poids du neurone 1’ et w 21 {\\displaystyle w_{21}} et w 22 {\\displaystyle w_{22}} sont les poids du neurone 2. Si les seuils sont nuls, hi sera la distance entre les points à classer et les points poids. La règle précédente tend à diminuer cette distance avec le point échantillon lorsque le neurone gagne. Elle doit donc permettre à chaque point poids de se positionner au milieu d'un nuage. Si on fixe initialement les poids de manière aléatoire, il se peut que l'un des neurones se positionne près des deux nuages et que l'autre se positionne loin de sorte qu'il ne gagne jamais. Ses poids ne pourront jamais évoluer alors que ceux de l'autre neurone vont le positionner au milieu des deux nuages. Le problème de ces neurones que l'on qualifie de morts peut être résolu en jouant sur les seuils. En effet, il suffit d'augmenter le seuil de ces neurones pour qu'ils commencent à gagner.\nApplications : ce type de réseau et la méthode d'apprentissage correspondant peuvent être utilisés en analyse de données afin de mettre en évidence des similitudes entre certaines données.\nS'agissant d'un modèle, les réseaux de neurones sont généralement utilisés dans le cadre de simulation logicielle. IMSL et Matlab disposent ainsi de bibliothèques dédiées aux réseaux de neurones. Cependant, il existe quelques implémentations matérielles des modèles les plus simples, comme la puce ZISC .\nSur les autres projets Wikimedia :"
}