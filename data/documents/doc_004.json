{
  "id": 4,
  "title": "Algorithme",
  "url": "https://fr.wikipedia.org/wiki/Algorithme",
  "date": "2025-11-26T21:43:52.071641",
  "content": "Ne doit pas être confondu avec Logarithme .\nUn algorithme est une suite finie et non ambiguë d'instructions et d’opérations permettant de résoudre une classe de problèmes [ 1 ] .\nLe domaine qui étudie les algorithmes est appelé l' algorithmique . On retrouve aujourd'hui des algorithmes dans de nombreuses applications informatiques, dont dans les systèmes permettant le fonctionnement des ordinateurs [ 2 ] , la cryptographie , le routage d' informations , la planification et l'utilisation optimale des ressources, le traitement d'images , le traitement de textes , la bio-informatique , l' intelligence artificielle , l'automatique, etc.\nL'algorithme peut être mis en forme de façon graphique dans un algorigramme ou organigramme de programmation.\nLe mot algorithme a une longue histoire.\n' Al-Khwârizmî (en arabe : الخوارزمي ) [ 3 ] , [ 4 ] est un mathématicien persan du IX e siècle, dont le nom est relatif au Khwarezm , une région située au Sud de la mer d'Aral . Le traité qu’il écrivit en arabe , au IX e siècle, sera traduit en latin au XII e siècle, sous le titre Algoritmi de numero Indorum . \"Algoritmie des nombres indiens\" [ 5 ] , [ 6 ] . Algoritmie est la latinisation de son nom par les traducteurs : Alchoarismi puis Algorismi, Algorismo, Algoritmi [ 7 ] .\nUn de ses ouvrages, Abrégé du calcul par la restauration et la comparaison , a d'ailleurs donné son nom à l' algèbre . Le titre de la traduction par Gilbert de Cremone en latin est Liber Maumeti filii Moysi Alchoarismi de Algebra et Almuquabala . On y retrouve traduit son nom : Maumeti filii Moysi Alchoarismi (Muhammad Ben Musa al Kwuwarizmi) et le fameux Alchoarismi.\nJoannes Sacrobosco , moine ayant étudié à Oxford , est reçu à l'université de la Sorbonne le 5 juin 1221 et élu professeur de Quadrivium peu après. C’est vers cette date qu’il compose De Algorismo [ 8 ] . Il est l'un des premiers docteurs du Moyen Âge à utiliser les écrits astronomiques des Arabes, considéré d'ailleurs  en Angleterre comme ayant introduit l'usage des « chiffres » ( sifer ) que le pape Sylvestre II avait tenté en vain de répandre plus tôt.\nEn 1240, Alexandre de Villedieu écrit son Carmen de Algorismo sur la science des chiffres.\nAlgoritmie désigne alors aussi ce nouveau système de numération , le système de numération de position avec le zéro [ 7 ] .\nSous l’influence de l’ancien espagnol algorismo , le mot apparaît aussi en français déjà vers 1230 sous la forme augorisme , puis algorisme au XIII e siècle, pour désigner le calcul en chiffres, l’ arithmétique . La forme moderne du terme reprend le latin médiéval algorithmus , altération influencée par arithmetica et d'autres, du grec ancien arithmos = nombre.\nEn 1842, Ada Lovelace écrit le premier algorithme de programmation de l'histoire. Elle le fait à partir de la machine analytique de Babbage et devient la première informaticienne de l'humanité [ 9 ] .\nUn algorithme est une méthode générale pour résoudre un type de problèmes. Il est dit correct lorsque, pour chaque instance du problème, il se termine en produisant la bonne sortie, c'est-à-dire qu'il résout le problème posé.\nL'efficacité d'un algorithme est mesurée notamment par :\nLes ordinateurs sur lesquels s'exécutent ces algorithmes ne sont pas infiniment rapides, car le temps de machine reste une ressource limitée, malgré une augmentation constante des performances des ordinateurs. Un algorithme sera donc dit performant s'il utilise avec parcimonie les ressources dont il dispose, c'est-à-dire le temps de processeur , la mémoire vive et, objet de recherches récentes, la consommation électrique . L’ analyse de la complexité des algorithmes permet de décrire l'évolution en temps calcul nécessaire pour amener un algorithme à son terme, lorsque la quantité de données à traiter grandit.\nL'émergence des langages de niveaux supérieurs pose le problème du temps :\nL'algorithme composé de boites peut ainsi être plus ou moins détaillé, précis.\nDonald Knuth (1938-) liste, comme prérequis d'un algorithme, cinq propriétés [ 10 ] :\nGeorge Boolos (1940-1996), philosophe et mathématicien, propose la définition suivante [ 11 ] :\nGérard Berry (1948-), chercheur en science informatique, en donne la définition grand public suivante [ 12 ] :\nLes entrées sont généralement associées à des capteurs et les sorties à des actions, actionneurs ou opérateurs (affichage, moteur, etc. ).\nLes algorithmes sont des objets historiquement dédiés à la résolution de problèmes arithmétiques, comme la multiplication de deux nombres. Ils ont été formalisés bien plus tard avec l'avènement de la logique mathématique et l'émergence des machines qui permettaient de les mettre en œuvre, à savoir les ordinateurs.\nLa plupart des algorithmes ne sont pas numériques.\nOn peut distinguer :\nVoir aussi : Liste de sujets généraux sur les algorithmes (en)\nL'algorithmique intervient de plus en plus dans la vie quotidienne [ 14 ] .\nLes progrès de ce qu'on appelle l' intelligence artificielle s'appuient sur un algorithmique de plus en plus complexe qui devient l'un des rouages cachés du Web 2.0 et des grands réseaux sociaux .\nDans la vie quotidienne, un glissement de sens s'est opéré, ces dernières années, dans le concept d'« algorithme » qui devient à la fois plus réducteur, puisque ce sont pour l'essentiel des algorithmes de gestion du big data , et d'autre part plus universel en ce sens qu'il intervient dans tous les domaines du comportement quotidien [ 18 ] [réf. incomplète] . La famille des algorithmes dont il est question effectue des calculs à partir de grandes masses de données (les big data ). Ils réalisent des classements, sélectionnent des informations et en déduisent un profil, en général de consommation, qui est ensuite utilisé ou exploité commercialement. Les implications sont nombreuses et touchent les domaines les plus variés [ 19 ] . Mais les libertés individuelles et collectives pourraient être finalement mises en péril [ 20 ] , comme le montre la mathématicienne américaine Cathy O'Neil dans le livre Weapons of Math Destruction , publié en 2016 et sorti en français en 2018 sous le titre Algorithmes : la bombe à retardement (aux éditions Les Arènes).\n« Aujourd’hui, les modèles mathématiques et les algorithmes prennent des décisions majeures, servent à classer et catégoriser les personnes et les institutions, influent en profondeur sur le fonctionnement des États sans le moindre contrôle extérieur. Et avec des effets de bords incontrôlables. […] Il s’agit d’un pouvoir utilisé contre les gens. Et pourquoi ça marche ? Parce que les gens ne connaissent pas les maths, parce qu’ils sont intimidés. C’est cette notion de pouvoir et de politique qui m’a fait réaliser que j’avais déjà vu ça quelque part. La seule différence entre les modèles de risque en finances et ce modèle de plus-value en science des données, c’est que, dans le premier cas, en 2008, tout le monde a vu la catastrophe liée à la crise financière. Mais, dans le cas des profs, personne ne voit l’échec. Ça se passe à un niveau individuel. Des gens se font virer en silence, ils se font humilier, ils ont honte d’eux [ 21 ] . »\nDans cet ouvrage, l'auteure alerte le lecteur sur les décisions majeures que nous déléguons aujourd'hui aux algorithmes dans des domaines aussi variés que l'éducation, la santé, l'emploi et la justice, sous prétexte qu'ils sont neutres et objectifs, alors que, dans les faits, ils donnent lieu à « des choix éminemment subjectifs, des opinions, voire des préjugés insérés dans des équations mathématiques » [ 22 ] .\nLa notion de bulle de filtre (ou filter bubble en anglais), popularisée par Eli Pariser , désigne l’effet des algorithmes de personnalisation utilisés par les plateformes en ligne qui isolent les utilisateurs dans une sorte de bulle en leur proposant des contenus correspondant à leurs préférences et croyances antérieures. En d’autres termes, l’exposition à des informations et opinions diversifiées est limitée, ayant pour conséquence de renforcer les biais cognitifs et les visions préexistantes de la réalité. Les auteurs J. Farchy et S. Tallec ont analysé l’impact de ces bulles de filtre sur la découverte de contenus culturels, tels que les films ou la musique. Leur étude révèle que, dans un environnement où les algorithmes favorisent la personnalisation au détriment de la diversité, la diversité culturelle est menacée [ 23 ] .\nL'opacité des algorithmes est l'une des raisons principales de ces critiques. Une meilleure information sur leur mode de fonctionnement spécifique permettrait de rendre plus clair le \"contrat social passé entre les internautes et les calculateurs\" [ 24 ] . La description pour chaque algorithme de son propre principe de classement de l'information aide l'utilisateur à mieux comprendre les choix proposés par l'algorithme et les résultats obtenus [ 25 ] .\nDepuis les années 2000 , l’usage croissant d’algorithmes dans des domaines variés (publicité, politique, services numériques) soulève des questions éthiques et sociétales. Souvent perçus comme des « boîtes noires », ces systèmes automatisés influencent les comportements individuels sans que leurs mécanismes internes soient toujours compréhensibles ou transparents.\nDes philosophes comme Wendell Wallach et Colin Allen ont interrogé la capacité de ces systèmes à prendre des décisions à portée morale, introduisant la notion d’« agents moraux artificiels » : des systèmes qui, sans être imputables comme les humains, peuvent néanmoins avoir un impact éthique significatif. Dans cette lignée, Martin Gibert insiste sur le rôle central de la programmation dans les choix moraux intégrés aux algorithmes : « Quelles règles implanter dans les robots, et comment le faire ? »\n« Les agents moraux artificiels (AMA) ne sont pas cependant des agents moraux au sens fort du terme. Contrairement aux humains, ils ne semblent pas imputables [sic] de leurs actes. Ils n'ont toutefois pas besoin de l'être pour prendre des décisions moralement significatives et soulever tout un tas de questions en éthique des algorithmes [ 26 ] . »\nUne approche sociologique des technologies algorithmiques [ 27 ] , portée notamment par les chercheur·e·s en Science and Technology Studies (STS), met en lumière la manière dont ces systèmes s’inscrivent dans des dynamiques sociales complexes. Loin d’être le produit d’intentions malveillantes ou de détournements délibérés, les biais et discriminations générés par ces technologies résultent de processus collectifs de conception, d’entraînement et de déploiement, façonnés par des structures sociales inégalitaires et des jeux d’acteurs aux intérêts multiples, parfois contradictoires.\nLes données mobilisées pour entraîner ces systèmes sont elles-mêmes issues de contextes marqués par des rapports sociaux — qu’ils soient raciaux, genrés ou économiques. En l’absence d’une analyse rigoureuse de ces structures, les technologies algorithmiques tendent à reproduire et amplifier les inégalités existantes, non par malveillance, mais parce qu’elles sont conçues et mises en œuvre dans un environnement social traversé par des normes, des hiérarchies et des logiques d’exclusion. Ce phénomène renvoie à ce que certain·e·s nomment le façonnement sociotechnique des technologies : les algorithmes ne sont pas neutres, ils sont le produit de choix techniques influencés par des pratiques professionnelles, des logiques économiques, des imaginaires sociaux et des contraintes institutionnelles.\nAinsi, les algorithmes incarnent une forme de priorisation de ce qui est techniquement exécutable, au détriment de la complexité sociale et humaine. Les décisions intégrées dans les modèles — que ce soit dans la sélection des données, les critères de classification, ou la manière dont les sorties sont interprétées — résultent de compromis entre acteurs (développeurs, entreprises, institutions) aux intérêts et responsabilités parfois flous ou dispersés.\n\" L’idée selon laquelle un simple accroissement des données pourrait éliminer les biais ignore ce point fondamental: les données ne sont pas neutres, elles sont le reflet de réalités sociales déjà marquées par des inégalités. \"\nUn exemple [ 28 ] marquant concerne les systèmes de reconnaissance d’images, tels que Google Cloud Vision ou Amazon Rekognition, qui attribuent davantage d’étiquettes liées à l’apparence aux femmes (« fille », « présentatrice télé »), tandis que les hommes se voient associés à des fonctions ou statuts (« homme d’affaires », « gentleman »). Ce constat ne relève pas d’une intention sexiste des programmeurs, mais d’un apprentissage à partir de données historiquement genrées, elles-mêmes issues de contextes où les rôles sociaux sont inégalement répartis. En ce sens, ces technologies renforcent des stéréotypes en les répliquant, sous couvert de neutralité technique.\nIl est donc essentiel de comprendre que les technologies algorithmiques ne « créent » pas les inégalités, mais qu’elles opèrent comme des amplificateurs de dynamiques sociales existantes. Leur prétendue objectivité masque en réalité leur ancrage dans des environnements sociohistoriques inégalitaires. Les processus techniques ne sont jamais isolés : ils prennent forme à travers des chaînes de décisions, des arbitrages politiques, économiques et normatifs, et des formes de rationalisation qui occultent, volontairement ou non, les implications sociales de ces choix.\nFinalement, penser les algorithmes exige une réflexion qui dépasse la technique : il s’agit de comprendre les conditions sociales de production des technologies, les rapports sociaux qui les traversent, et les effets sociaux qu’elles produisent. Sans cela, les tentatives de \"corriger\" les biais risqueraient de rester superficielles, et les inégalités de continuer d’être inscrites dans des systèmes perçus comme neutres ou universels.\nAu-delà des biais involontaires [ 29 ] , les algorithmes peuvent aussi être intentionnellement détournés à des fins idéologiques ou politiques. En juillet 2024, une étude de l’ Institute for Strategic Dialogue a révélé que certains utilisateurs de TikTok affiliés à l’extrême droite manipulaient l’algorithme de recommandation de la plateforme pour diffuser, de manière dissimulée, des discours d’ Adolf Hitler . En insérant des extraits entre des séquences musicales ou des contenus populaires, ces comptes contournent les mécanismes de modération tout en exploitant les logiques de viralité du système.\nCes pratiques illustrent une tendance plus large : les algorithmes, loin d’être neutres, participent activement à la structuration de l’espace public numérique. Qu’il s’agisse de biais involontaires ou d’instrumentalisation délibérée, les enjeux éthiques, sociaux et politiques liés à leur usage appellent à une réflexion collective sur leur conception et leur gouvernance.\nSur les autres projets Wikimedia :"
}