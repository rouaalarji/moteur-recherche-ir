{
  "id": 64,
  "title": "Superordinateur",
  "url": "https://fr.wikipedia.org/wiki/Superordinateur",
  "date": "2025-11-29T22:29:20.879913",
  "content": "Pour les articles homonymes, voir HPC .\nUn superordinateur ou supercalculateur est un ordinateur conçu pour atteindre les plus hautes performances possibles avec les techniques connues lors de sa conception, en particulier en ce qui concerne la vitesse de calcul . Pour des raisons de performance, c'est presque toujours un ordinateur central , dont les tâches sont effectuées en traitement par lots .\nLa science des superordinateurs est appelée « calcul haute performance » (en anglais : high-performance computing ou HPC). Cette discipline se divise en deux : la partie matérielle (conception électronique de l'outil de calcul) et la partie logicielle (adaptation logicielle du calcul à l'outil). Ces deux parties font appel à des champs de connaissances différents.\nLes premiers superordinateurs (ou supercalculateurs) apparaissent dans les années 1960 .\nEn 1961, IBM développe, à l’instigation du Lawrence Livermore Laboratory [ 2 ] , l’ IBM Stretch ou IBM 7030, dont une unité est exploitée en France [ 3 ] en 1963.\nÀ cette époque, et jusque dans les années 1970 , le plus important constructeur mondial de superordinateurs est la société Control Data Corporation (CDC), avec son concepteur Seymour Cray [ 4 ] . Par la suite, Cray Research , fondée par Seymour Cray après son départ de CDC, prend l’avantage sur ses autres concurrents, jusqu’aux alentours de l'année 1990. Dans les années 1980 , à l’image de ce qui s’était produit sur le marché des micro-ordinateurs des années 1970, de nombreuses petites sociétés se lancèrent sur ce marché, mais la plupart disparaissent dans le « crash » du marché des superordinateurs [ 5 ] , au milieu des années 1990 .\nCe que désigne le terme superordinateur varie avec le temps car, comme le suggère la Loi de Moore , les ordinateurs les plus puissants du monde à un moment donné tendent à être égalés, puis dépassés, par des machines d’utilisation courante plusieurs années après. Les premiers superordinateurs CDC étaient de simples ordinateurs mono- processeurs (mais possédant parfois jusqu’à dix processeurs périphériques pour les entrées-sorties ) environ dix fois plus rapides que la concurrence. Dans les années 1970, la plupart des superordinateurs adoptent un processeur vectoriel , qui effectue le décodage d’une instruction une seule fois pour l’appliquer à toute une série d’ opérandes .\nC’est seulement vers la fin des années 1980 que la technique des systèmes massivement parallèles est adoptée, avec l’utilisation dans un même superordinateur de milliers de processeurs. Depuis le milieu des années 1990, certains de ces superordinateurs parallèles utilisent des microprocesseurs de type « RISC », conçus pour des ordinateurs de série, comme les PowerPC [ 6 ] ou les PA-RISC . D’autres supercalculateurs utilisent des processeurs de moindre coût, de type « CISC », microprogrammés en RISC dans la puce électronique ( AMD ou Intel ) : le rendement en est un peu moins élevé, mais le canal d’accès à la mémoire — souvent un goulet d’étranglement — est bien moins sollicité.\nAu XXI e siècle , les superordinateurs sont le plus souvent conçus comme des modèles uniques par des constructeurs informatiques « traditionnels » comme International Business Machines (IBM), Hewlett-Packard (HP), ou Bull , qu’ils aient derrière eux une longue tradition en la matière (IBM) ou qu’ils aient racheté dans les années 1990 des entreprises spécialisées, alors en difficulté, pour acquérir de l’expérience dans ce domaine.\nLes superordinateurs sont utilisés pour toutes les tâches qui nécessitent une très forte puissance de calcul [ 7 ] , comme les prévisions météorologiques , l’ étude du climat (à ce sujet, voir les programmes financés par le G8-HORCs ), la modélisation d'objets chimiques ( calcul de structures et de propriétés , modélisation moléculaire , etc. ), les simulations physiques (simulations aérodynamiques , calculs de résistance des matériaux , simulation d' explosion d' arme nucléaire , étude de la fusion nucléaire , etc. ), la cryptanalyse ou les simulations en finance et en assurance ( calcul stochastique ).\nLes institutions de recherche civiles et militaires comptent parmi les plus gros utilisateurs de superordinateurs.\nEn France , on trouve ces machines dans les centres nationaux de calculs universitaires, tels que l' Institut du développement et des ressources en informatique scientifique (IDRIS), le Centre informatique national de l'enseignement supérieur (CINES), mais aussi au Commissariat à l'énergie atomique et aux énergies alternatives (CEA), dans certaines grandes entreprises, comme Total , EDF , Météo-France [ 8 ] ou encore à la Direction générale de la Sécurité extérieure (DGSE) pour ses besoins en cryptanalyse .\nLes superordinateurs tirent leur supériorité sur les ordinateurs conventionnels à la fois grâce à :\nIls sont presque toujours conçus spécifiquement pour un certain type de tâches (le plus souvent des calculs numériques scientifiques : calcul matriciel ou vectoriel ) et ne cherchent pas de performances particulières dans d'autres domaines.\nL’architecture mémorielle des supercalculateurs est étudiée pour fournir en continu les données à chaque processeur afin d’exploiter au maximum sa puissance de calcul . Les performances supérieures de la mémoire (meilleurs composants et meilleure architecture) expliquent pour une large part l’avantage des superordinateurs sur les ordinateurs classiques.\nLeur système d’ entrée/sortie ( bus ) est conçu pour fournir une large bande passante , la latence étant moins importante puisque ce type d’ordinateur n’est pas conçu pour traiter des transactions .\nComme pour tout système parallèle, la loi d’Amdahl s’applique, les concepteurs de superordinateurs consacrant une partie de leurs efforts à éliminer les parties non parallélisables du logiciel et à développer des améliorations matérielles pour supprimer les goulots d'étranglement restants.\nD'une part, les superordinateurs ont souvent besoin de plusieurs mégawatts de puissance électrique . Cette alimentation doit aussi être de qualité. En conséquence, ils produisent une grande quantité de chaleur et doivent donc être refroidis pour fonctionner normalement. Le refroidissement de ces ordinateurs (par exemple à air ) pose souvent des problèmes importants de climatisation .\nD'autre part, les données ne peuvent circuler plus vite que la vitesse de la lumière entre deux parties d'un ordinateur . Lorsque la taille d’un superordinateur dépasse plusieurs mètres, le temps de latence entre certains composants se compte en dizaines de nanosecondes . Les éléments sont donc disposés pour limiter la longueur des câbles qui relient les composants. Sur le Cray-1 ou le Cray- II , par exemple, ils étaient disposés en cercle .\nDe nos jours, ces ordinateurs sont capables de traiter et de communiquer de très importants volumes de données en très peu de temps. La conception doit assurer que ces données puissent être lues, transférées et stockées rapidement. Dans le cas contraire, la puissance de calcul des processeurs serait sous-exploitée ( goulot d’étranglement ).\nEn 1993 , l' Institut de Physique du Globe de Paris (IPGP) opère un ordinateur CM-5/128 qui utilise des processeurs SuperSPARC , il est classé 25 e au TOP500 [ 20 ] . Trois ans plus tard, en 1996 , l' Institut du développement et des ressources en informatique scientifique (IDRIS) parvient à atteindre la 12 e place mondiale avec le T3E construit par Cray [ 21 ] .\nÀ la mi- 2002 , le plus puissant des supercalculateurs français se classe 4 e au TOP500, c'est le TERA basé sur des processeurs Alpha à 1 GHz ( AlphaServer SC45 ) et développé par Hewlett-Packard [ 22 ] ; il appartenait au Commissariat à l'énergie atomique (CEA). En janvier 2006 , le TERA-10 de Bull lui succède, il génère une puissance de calcul de 60 téra FLOPS et se placera au 5 e rang mondial du TOP500 [ 23 ] .\nEn juin 2008 , l'IDRIS et son Blue Gene/P Solution d' IBM affiche, selon le test LINPACK , une puissance de 120 téraflops et remporte la 10 e place [ 24 ] .\nEn novembre 2009 , la première machine française a pour nom Jade . De type « SGI Altix (en) » elle est basée au Centre informatique national de l'enseignement supérieur (CINES) de Montpellier . Ce supercalculateur se classe au 28 e rang mondial avec 128 téraflops au test LINPACK. Peu après, la configuration de la machine Jade est complétée pour atteindre une performance de 237 téraflops. La machine passe en juin 2010 au 18 e rang du TOP500 [ 25 ] . C’est alors le troisième système informatique européen et le premier français, il est destiné à la recherche publique .\nEn novembre 2010 , le record français est détenu par le TERA-100 de Bull . Installé au CEA à Bruyères-le-Châtel pour les besoins de la simulation militaire nucléaire française , avec une performance de 1 050 téraflops, cette machine se hisse au 6 e rang mondial et gagne le 1 er rang européen [ 26 ] . Elle est constituée de 17 296 processeurs Intel Xeon 7500 dotés chacun de huit cœurs et connectés par un réseau de type InfiniBand .\nEn mars 2012 , Curie , un système conçu par Bull pour le GENCI , installé sur le site du Très Grand Centre de Calcul (TGCC) à Bruyères-le-Châtel, dispose d'une puissance de 1,359 pétaflops [ 27 ] . Il sera le supercalculateur le plus puissant de France en prenant la 9 e place du classement mondial [ 28 ] . Il est conçu pour délivrer 2 pétaflops.\nEn janvier 2013 , les systèmes Ada et Turing construits par IBM sont installés à l'IDRIS d' Orsay . La somme de leur puissance dépasse le pétaflops. Ces deux machines sont à la disposition des chercheurs. En mars 2013 , le supercalculateur Pangea [ 29 ] détenu par la société Total est inauguré, il devient le système le plus performant jamais installé en France. Sa puissance de calcul s'élève à 2,3 pétaflops. Équivalant à 27 000 ordinateurs de bureau réunis, il obtient la 11 e place mondiale [ 30 ] .\nEn janvier 2015 , le système Occigen , conçu par Bull, Atos technologies, pour le GENCI est installé sur le site du CINES ; il est doté d'une puissance de 2,1 pétaflops. Il se situait en 26 e position au classement mondial du TOP500 de novembre 2014 [ 31 ] .\nEn mars 2016 , Total annonce avoir triplé la capacité de calcul de son supercalculateur Pangea , passant à une puissance de calculs de 6,7 pétaflops en pics de performance et de 5,28 pétaflops en puissance utilisable. Cela lui permet de retrouver le 11 e rang au TOP500 [ 30 ] et le place ainsi en tête du secteur industriel mondial [ 32 ] .\nEn juin 2022 , le GENCI met en service Adastra , un superordinateur fourni par HPE - Cray hébergé au CINES. Ses 46,10 pétaflops lui permettent de gagner le 10 e rang mondial en matière de performances de calcul [ 33 ] .\nEn mai 2025 , l'extension du supercalculateur Jean Zay, le Jean Zay 4 est mis en service par l' IDRIS . Il développe une puissance de 125,9 pétaflops et devient la machine la plus rapide de France [ 34 ] .\nL'essor des supercalculateurs a vu Linux devenir le système d'exploitation équipant la majorité des 500 supercalculateurs les plus puissants de la planète [ 9 ] , [ 35 ] , Unix perdant progressivement du terrain face à Linux, mais occupant pendant un temps une place de choix sur le marché des supercalculateurs (5 %). [ réf. souhaitée]\nWindows ne fut exécuté que par deux des 500 supercalculateurs les plus puissants de la planète, soit 0,4 % [ 9 ] , tandis que BSD n'était présent que sur une seule machine du top 500 , soit 0,2 %. Enfin, les autres configurations (« Mixed », soit un ensemble de plusieurs types de systèmes d'exploitation) représentaient 4,6 %. [ réf. souhaitée]\nEn novembre 2017 , Linux équipe la totalité des 500 superordinateurs les plus puissants au monde [ 36 ] .\nPour un article plus général, voir L'intelligence artificielle et les jeux .\nSur les autres projets Wikimedia :"
}